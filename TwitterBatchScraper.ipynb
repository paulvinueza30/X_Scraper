{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install dependencies (safe to run in Google Colab)\n",
    "!pip install --quiet playwright nest_asyncio pandas\n",
    "!playwright install-deps\n",
    "!playwright install chromium\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import asyncio\n",
    "import random\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, Page\n",
    "\n",
    "# Allow nested event loops in environments like Google Colab\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def _parse_compact_count(raw: Optional[str]) -> int:\n",
    "    \"\"\"Convert counters like '1,234' or '2.5K' to integers.\"\"\"\n",
    "    if not raw:\n",
    "        return 0\n",
    "    text = raw.replace(',', '').strip()\n",
    "    if not text:\n",
    "        return 0\n",
    "    multiplier = 1\n",
    "    if text[-1] in {'K', 'M', 'B'}:\n",
    "        suffix = text[-1]\n",
    "        text = text[:-1]\n",
    "        multiplier = {'K': 1_000, 'M': 1_000_000, 'B': 1_000_000_000}[suffix]\n",
    "    try:\n",
    "        return int(float(text) * multiplier)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class TwitterPlaywrightScraper:\n",
    "    \"\"\"Scrape public tweets from multiple profiles using Playwright.\"\"\"\n",
    "\n",
    "    def __init__(self, usernames: List[str], headless: bool = True) -> None:\n",
    "        self.usernames = usernames\n",
    "        self.headless = headless\n",
    "        self.user_agent = (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "            \"(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "        )\n",
    "        self._playwright = None\n",
    "        self._browser = None\n",
    "        self._context = None\n",
    "        self._page: Optional[Page] = None\n",
    "        self.tweets: List[Dict] = []\n",
    "\n",
    "    async def _start(self) -> None:\n",
    "        if self._playwright:\n",
    "            return\n",
    "        self._playwright = await async_playwright().start()\n",
    "        self._browser = await self._playwright.chromium.launch(\n",
    "            headless=self.headless,\n",
    "            args=[\n",
    "                \"--disable-blink-features=AutomationControlled\",\n",
    "                \"--disable-infobars\",\n",
    "                \"--no-sandbox\",\n",
    "            ],\n",
    "        )\n",
    "        self._context = await self._browser.new_context(\n",
    "            user_agent=self.user_agent,\n",
    "            viewport={\"width\": 1366, \"height\": 768},\n",
    "        )\n",
    "        self._page = await self._context.new_page()\n",
    "\n",
    "    async def _stop(self) -> None:\n",
    "        if self._context:\n",
    "            await self._context.close()\n",
    "        if self._browser:\n",
    "            await self._browser.close()\n",
    "        if self._playwright:\n",
    "            await self._playwright.stop()\n",
    "        self._context = self._browser = self._playwright = self._page = None\n",
    "\n",
    "    async def _extract_tweet(self, tweet_element) -> Optional[Dict]:\n",
    "        if not tweet_element:\n",
    "            return None\n",
    "        content_el = await tweet_element.query_selector('[data-testid=\"tweetText\"]')\n",
    "        text_content = await content_el.inner_text() if content_el else await tweet_element.inner_text()\n",
    "        text_content = \" \".join(text_content.split())\n",
    "\n",
    "        time_el = await tweet_element.query_selector('time')\n",
    "        timestamp = await time_el.get_attribute('datetime') if time_el else None\n",
    "        permalink = None\n",
    "        if time_el:\n",
    "            permalink = await time_el.evaluate(\"el => el.closest('a')?.href || null\")\n",
    "\n",
    "        reply_el = await tweet_element.query_selector('[data-testid=\"reply\"]')\n",
    "        retweet_el = await tweet_element.query_selector('[data-testid=\"retweet\"]')\n",
    "        like_el = await tweet_element.query_selector('[data-testid=\"like\"]')\n",
    "\n",
    "        replies = _parse_compact_count(await reply_el.inner_text() if reply_el else \"0\")\n",
    "        retweets = _parse_compact_count(await retweet_el.inner_text() if retweet_el else \"0\")\n",
    "        likes = _parse_compact_count(await like_el.inner_text() if like_el else \"0\")\n",
    "\n",
    "        return {\n",
    "            \"text\": text_content,\n",
    "            \"date\": timestamp,\n",
    "            \"replies\": replies,\n",
    "            \"retweets\": retweets,\n",
    "            \"likes\": likes,\n",
    "            \"permalink\": permalink,\n",
    "        }\n",
    "\n",
    "    async def scrape_profile(self, username: str, limit: int = 20) -> List[Dict]:\n",
    "        await self._start()\n",
    "        assert self._page\n",
    "        page = self._page\n",
    "        await page.goto(f\"https://x.com/{username}\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_selector('[data-testid=\"tweet\"]', timeout=20000)\n",
    "\n",
    "        collected: List[Dict] = []\n",
    "        seen_ids = set()\n",
    "\n",
    "        while len(collected) < limit:\n",
    "            tweets = await page.query_selector_all('[data-testid=\"tweet\"]')\n",
    "            for tweet in tweets:\n",
    "                data = await self._extract_tweet(tweet)\n",
    "                if not data:\n",
    "                    continue\n",
    "                status_id = None\n",
    "                if data.get(\"permalink\"):\n",
    "                    status_id = data[\"permalink\"].split('/')[-1].split('?')[0]\n",
    "                if status_id and status_id in seen_ids:\n",
    "                    continue\n",
    "                if status_id:\n",
    "                    seen_ids.add(status_id)\n",
    "                data[\"username\"] = username\n",
    "                collected.append(data)\n",
    "                if len(collected) >= limit:\n",
    "                    break\n",
    "            if len(collected) >= limit:\n",
    "                break\n",
    "\n",
    "            scroll_amount = random.randint(600, 1200)\n",
    "            await page.evaluate(\"window.scrollBy(0, arguments[0]);\", scroll_amount)\n",
    "            await page.wait_for_timeout(random.randint(2000, 4000))\n",
    "            try:\n",
    "                await page.wait_for_load_state(\"networkidle\", timeout=5000)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        return collected[:limit]\n",
    "\n",
    "    async def scrape_all(self, limit: int = 20) -> pd.DataFrame:\n",
    "        await self._start()\n",
    "        try:\n",
    "            for user in self.usernames:\n",
    "                profile_tweets = await self.scrape_profile(user, limit=limit)\n",
    "                self.tweets.extend(profile_tweets)\n",
    "        finally:\n",
    "            await self._stop()\n",
    "        return self.to_dataframe()\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(self.tweets)\n",
    "\n",
    "    def save_to_csv(self, filename: str) -> None:\n",
    "        df = self.to_dataframe()\n",
    "        df.to_csv(filename, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "usernames = [\"SpaceX\", \"NASA\"]\n",
    "scraper = TwitterPlaywrightScraper(usernames=usernames, headless=True)\n",
    "\n",
    "async def main():\n",
    "    df = await scraper.scrape_all(limit=20)\n",
    "    print(df.head())\n",
    "    scraper.save_to_csv(\"tweets.csv\")\n",
    "\n",
    "# Use a running event loop if present (e.g., in Google Colab)\n",
    "loop = asyncio.get_event_loop()\n",
    "if loop.is_running():\n",
    "    task = loop.create_task(main())\n",
    "    await task\n",
    "else:\n",
    "    loop.run_until_complete(main())\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}